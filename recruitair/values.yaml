frontend:
  enabled: true
  image:
    repository: ghcr.io/mlops-2526q1-mds-upc/recruitair/frontend
    tag: "0.1.4"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 8080
  autoscaling:
    minReplicas: 1
    maxReplicas: 2
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  ingress:
    enabled: true
    host: localhost
    prefix: /frontend
    tls:
      enabled: false
      # secretName: frontend-tls

dispatcher:
  replicaCount: 1
  db:
    name: dispatcher_db
    username: dispatcher_user
  evaluator:
    httpTimeout: 30
    batchSize: 1
    image:
      repository: ghcr.io/mlops-2526q1-mds-upc/recruitair/dispatcher-evaluator
      tag: "0.3.0"
      pullPolicy: IfNotPresent
    metrics:
      enabled: true
      service:
        type: ClusterIP
        port: 8000
  extractor:
    httpTimeout: 180 # Three minutes. Because in local testing, docker is slow to respond.
    batchSize: 1
    image:
      repository: ghcr.io/mlops-2526q1-mds-upc/recruitair/dispatcher-extractor
      tag: "0.3.0"
      pullPolicy: IfNotPresent
    metrics:
      enabled: true
      service:
        type: ClusterIP
        port: 8000
  api:
    image:
      repository: ghcr.io/mlops-2526q1-mds-upc/recruitair/dispatcher-api
      tag: "0.3.0"
      pullPolicy: IfNotPresent
    service:
      type: ClusterIP
      port: 8000
    autoscaling:
      minReplicas: 1
      maxReplicas: 2
      targetCPUUtilizationPercentage: 80
      targetMemoryUtilizationPercentage: 80
    ingress:
      enabled: true
      host: ""
      prefix: /api
      tls:
        enabled: false
        # secretName: dispatcher-api-tls
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "512Mi"
        cpu: "200m"
  migration:
    image:
      repository: ghcr.io/mlops-2526q1-mds-upc/recruitair/dispatcher-migration
      tag: "0.3.0"
      pullPolicy: IfNotPresent
postgres:
  adminSecretName: postgres-secret
  image:
    repository: postgres
    tag: "16-alpine"
    pullPolicy: IfNotPresent
  persistence:
    size: 10Gi
    storageClass: "standard"
imagePullSecrets:
  - name: regcred
extractor:
  service:
    port: 8081
evaluator:
  service:
    port: 8082

evaluator:
  awsSecret: aws-creds # Comment this out if running inside AWS, thus using IAM roles.
  image:
    repository: ghcr.io/mlops-2526q1-mds-upc/recruitair/evaluator-api
    tag: "0.2.1"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 8000
  autoscaling:
    minReplicas: 1
    maxReplicas: 2
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  ingress:
    enabled: true
    host: localhost
    prefix: /evaluator
    tls:
      enabled: false
      # secretName: evaluator-api-tls
  model:
    name: criteria-evaluation
    version: "1"
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "200m"
  cache:
    size: 5Gi
    storageClass: "standard"

extractor:
  model:
    name: dolphin3
    version: 8b
  prompt:
    name: criteria-extraction
    version: "1"
  api:
    image:
      repository: ghcr.io/mlops-2526q1-mds-upc/recruitair/extractor-api
      tag: "0.2.1"
      pullPolicy: IfNotPresent
    service:
      type: ClusterIP
      port: 8000
    autoscaling:
      minReplicas: 1
      maxReplicas: 2
      targetCPUUtilizationPercentage: 80
      targetMemoryUtilizationPercentage: 80
    ingress:
      enabled: true
      host: ""
      prefix: /extractor
      tls:
        enabled: false
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "512Mi"
        cpu: "200m"
  ollama:
    image:
      repository: ollama/ollama
      tag: 0.13.1
      pullPolicy: IfNotPresent
    service:
      type: ClusterIP
      port: 11434
    autoscaling:
      minReplicas: 1
      maxReplicas: 2
      targetCPUUtilizationPercentage: 80
      targetMemoryUtilizationPercentage: 80
    ingress:
      enabled: true
      host: ""
      prefix: /ollama
      tls:
        enabled: false
        # secretName: extractor-ollama-tls
    persistence:
      size: 10Gi
      storageClass: "standard"

mlflow:
  trackingUri: https://ml-4cb370e118ec407c83eed254868ebce1.ecs.eu-north-1.on.aws

ingress:
  className: alb

prometheus:
  image:
    repository: prom/prometheus
    tag: "v3.8.0"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 9090
  ingress:
    enabled: false
    host: localhost
    prefix: /prometheus
    tls:
      enabled: false
      # secretName: prometheus-tls
  persistence:
    size: 10Gi
    storageClass: "standard"

grafana:
  adminCredentialsSecretName: grafana-admin-credentials
  image:
    repository: grafana/grafana
    tag: "12.1"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 3000
  ingress:
    enabled: true
    host: localhost
    prefix: /grafana
    tls:
      enabled: false
      # secretName: grafana-tls
  persistence:
    size: 10Gi
    storageClass: "standard"
